{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/koki0702/zerobook3/blob/master/notebook/en/step06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qD_v5BgmSNeK"
   },
   "source": [
    "**The code implemented in the previous step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "1ItduEGlSNeK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Variable:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "\n",
    "class Function:\n",
    "    def __call__(self, input):\n",
    "        x = input.data\n",
    "        y = self.forward(x)\n",
    "        output = Variable(y)\n",
    "        self.input = input\n",
    "        self.output = output\n",
    "        return output\n",
    "\n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class Square(Function):\n",
    "    def forward(self, x):\n",
    "        return x ** 2\n",
    "\n",
    "\n",
    "class Exp(Function):\n",
    "    def forward(self, x):\n",
    "        return np.exp(x)\n",
    "\n",
    "\n",
    "def numerical_diff(f, x, eps=1e-4):\n",
    "    x0 = Variable(x.data - eps)\n",
    "    x1 = Variable(x.data + eps)\n",
    "    y0 = f(x0)\n",
    "    y1 = f(x1)\n",
    "    return (y1.data - y0.data) / (2 * eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b64KOJJASNeO"
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xP5kwa-3-9Ff"
   },
   "source": [
    "# Step 6: Back-propagation by hand.\n",
    "\n",
    "In the previous step, we explained how backpropagation works. In this step, we will extend the previous `Variable` and `Function` classes to implement the back-propagation to get the derivative. First, let's take a look at the `Variable` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Additional implementation of the Variable class\n",
    "\n",
    "Now, let's implement the `Variable` class for backpropagation. To do so, we extend it so that it has a corresponding differentiated value (`grad`) in addition to the normal value (`data`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Variable:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.grad = None  # Added code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a new instance variable called `grad`, as shown above. We assume that the instance variables `data` and `grad` are both multi-dimensional arrays (`ndarray`) of NumPy. Also, `grad` is initialized with `None` and set to its value when the derivative is actually computed by back-propagation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>WARNING</b>\n",
    "\n",
    "Derivatives on multiple variables, such as vectors and matrices, are called gradients. For this reason, the <code>Variable</code> class has a variable called <code>grad</code>, which is short for gradient.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Additional implementation of Function class\n",
    "\n",
    "This is followed by the `Function` class. In the previous steps, the `Function` class had the ability to forward-propagate (the `forward` method) with normal computation. In addition to this, we are adding two new features\n",
    "\n",
    " * The backward propagation feature (the `backward` method) for calculating the derivative.\n",
    " * Ability to keep the input `Variable` instance when calling a `forward` method.\n",
    "\n",
    "The following code implements these two points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Function:\n",
    "    def __call__(self, input):\n",
    "        x = input.data\n",
    "        y = self.forward(x)\n",
    "        output = Variable(y)\n",
    "        self.input = input           # Added code\n",
    "        return output\n",
    "\n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def backward(self, gy):          # Added code\n",
    "        raise NotImplementedError()  # Added code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the code above, the `__call__` method sets the input `input` to an instance variable. Now, when the `backward` method is called, we can use the `Variable` instance entered into the function as `self.input`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Additional implementation of Square and Exp classes\n",
    "\n",
    "We then implement the backward propagation of a specific function (`backward`). Let's start with the `Square` class that computes the squares. This can be implemented as follows, since the derivative of $y=x^2$ is $\\frac{dy}{dx} = 2x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Square(Function):\n",
    "    def forward(self, x):\n",
    "        y = x ** 2\n",
    "        return y\n",
    "\n",
    "    def backward(self, gy):\n",
    "        x = self.input.data\n",
    "        gx = 2 * x * gy\n",
    "        return gx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the `backward` method for backpropagation, as described above. The argument `gy` of this method is an instance of `ndarray`, which is passed the derivative from the output side. The result of the `backward` method is the value obtained by multiplying the derivative passed in the argument by the derivative of $y=x^2$. The returned result will be propagated further in the direction of the input.\n",
    "\n",
    "Next is the `Exp` class, which computes $y=e^x$. This can be implemented as follows, since $\\frac{dy}{dx} = e^x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Exp(Function):\n",
    "    def forward(self, x):\n",
    "        y = np.exp(x)\n",
    "        return y\n",
    "\n",
    "    def backward(self, gy):\n",
    "        x = self.input.data\n",
    "        gx = np.exp(x) * gy\n",
    "        return gx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Implementing Backpropagation\n",
    "\n",
    "That's all we need to do. Here, we try to calculate the derivative of the calculation shown in **Figure 6-1** using back-propagation.\n",
    "\n",
    "<br>![img1-12](images/1-12.png)\n",
    "\n",
    "**Figure 6-1** Composition function for back-propagation<br><br>\n",
    "\n",
    "First, the code for forward propagation in **Figure 6-1** is shown next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = Square()\n",
    "B = Exp()\n",
    "C = Square()\n",
    "\n",
    "x = Variable(np.array(0.5))\n",
    "a = A(x)\n",
    "b = B(a)\n",
    "y = C(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Subsequently, we find the derivative of `y` by back propagation. It calls the `backward` method of each function in the reverse order of forward propagation. The reverse propagation in this case can be expressed as a computational graph, as shown in **Figure 6-2**.\n",
    "\n",
    "<br>![img1-13](images/1-13.png)\n",
    "\n",
    "**Figure 6-2** Computational graph of backward propagation<br><br>\n",
    "\n",
    "**Figure 6-2** shows the order in which you should call the `backward` method of each function. You can also set the result of the `backward` method to the `grad` of any variable. So, here is the implementation of backward propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.297442541400256\n"
     ]
    }
   ],
   "source": [
    "y.grad = np.array(1.0)\n",
    "b.grad = C.backward(y.grad)\n",
    "a.grad = B.backward(b.grad)\n",
    "x.grad = A.backward(a.grad)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backward propagation starts with $\\frac{dy}{dy} = 1$. Therefore, the derivative of the output `y` is set to `np.array(1.0)`. Then, call the `backward` method in the order of `C` → `B` → `A`. This will give us the derivative for each variable.\n",
    "\n",
    "Running the above code, the result of `x.grad` is 3.297442541400256. This is the derivative of `y` with respect to `x`. Incidentally, the result for the numerical derivative in **Figure 6-2** is 3.2974426293330694, so we can see that the two results are almost identical. From this, it can be inferred that backpropagation is implemented correctly, or more accurately, with a high probability of being implemented correctly.\n",
    "\n",
    "This is the implementation of back-propagation. We were able to do it correctly, but we manually--that is, by our coding--specified the backward propagation order of `C` → `B` → `A`. The next step is to automate this manual process."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "step06.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
